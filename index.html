<!DOCTYPE html>
<html lang="zh-TW">
<head>
   <meta charset="UTF-8">
   <meta name="viewport" content="width=device-width, initial-scale=1.0">
   <title>勤美患者拍照工具.測試版</title>

   <script src="https://cdn.tailwindcss.com"></script>
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
   <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">

   <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
   <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
   <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

   <!-- Updated Face-API.js CDN to unpkg.com for better reliability -->
   <script src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>

   <style>
       body {
           font-family: 'Inter', sans-serif;
       }
       @keyframes ping-once {
           0% { transform: translate(-50%, -50%) scale(0.2); opacity: 1; }
           80% { transform: translate(-50%, -50%) scale(1.2); opacity: 0; }
           100% { transform: translate(-50%, -50%) scale(1.2); opacity: 0; }
       }
       .animate-ping-once {
           animation: ping-once 1s cubic-bezier(0, 0, 0.2, 1) forwards;
       }
       .video-container {
           width: 100%;
           height: 70vh;
           max-height: 800px;
           display: flex;
           align-items: center;
           justify-content: center;
           overflow: hidden;
           position: relative;
           background-color: #000;
       }
       .video-container video {
           width: 100%;
           height: 100%;
           object-fit: contain;
       }
       .overlay-elements {
           position: absolute;
           top: 0;
           left: 0;
           width: 100%;
           height: 100%;
           pointer-events: none;
           display: flex;
           align-items: center;
           justify-content: center;
       }
       .modal-overlay {
           position: fixed;
           top: 0;
           left: 0;
           right: 0;
           bottom: 0;
           background-color: rgba(0, 0, 0, 0.7);
           display: flex;
           align-items: center;
           justify-content: center;
           z-index: 100;
       }
       .modal-content {
           background-color: white;
           padding: 2.5rem;
           border-radius: 1.5rem;
           box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3);
           max-width: 90%;
           width: 500px;
           text-align: center;
           position: relative;
           animation: fadeIn 0.3s ease-out;
       }
       @keyframes fadeIn {
           from { opacity: 0; transform: scale(0.9); }
           to { opacity: 1; transform: scale(1); }
       }
       /* This class is now a container, styling is done inside the HTML */
       .modal-message {
           margin-bottom: 2rem;
       }
       .modal-close-button {
           background-color: #4299e1;
           color: white;
           padding: 0.75rem 2rem;
           border-radius: 9999px;
           font-size: 1.125rem;
           font-weight: bold;
           border: none;
           cursor: pointer;
           transition: background-color 0.3s ease, transform 0.2s ease;
           box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
       }
       .modal-close-button:hover {
           background-color: #3182ce;
           transform: translateY(-2px);
       }
       .modal-close-button:active {
           transform: translateY(0);
           box-shadow: none;
       }
   </style>
</head>
<body>
   <div id="root"></div>

   <script type="text/babel">
       const { useRef, useEffect, useState, useCallback } = React;
       const { createRoot } = ReactDOM;

       // --- 多語言文本 (保留上次的優化) ---
       const translations = {
           'zh-TW': {
                title: "勤美患者拍照工具.測試版",
                home: "首頁",
                introTitle: "勤美患者拍照工具",
                introDesc1: "此工具旨在協助牙醫師快速、便捷地拍攝患者的臉部照片，",
                introDesc2: "這些照片將作為勤美技師製作假牙時的重要參考依據。",
                introDesc3: "本次操作將引導您拍攝3個方向：",
                introAngles: "正面、側面、側面45°",
                introDesc4: "請依照提示操作，感謝您的配合！",
                startShooting: "開始拍照",
                testVersionNote: "此軟體為測試版本，可能因手機型號差異而無法正常運作。若您遇到任何問題，請隨時與我們聯繫，以便我們進行優化與修正。感謝您的理解與支持。",
                geminiCredit: "此軟體由 Google Gemini 協助製作",
                shooting: "拍照中",
                pleaseShoot: "請拍攝患者的",
                facePhoto: "臉部照片",
                faceDetection: {
                    noFace: "偵測人臉中... 請將人臉置於取景器中。",
                    lookStraight: "請患者直視鏡頭。",
                    centerFace: "請將人臉正面置中並確保輪廓完整露出。",
                    ready: "✅ 人臉已就緒，可以拍照！",
                    readySide: "✅ 已偵測到人臉，可以拍照！",
                    detectingSide: "偵測人臉中... 請將人臉置於畫面中央。",
                },
                zoomIn: "放大",
                zoomOut: "縮小",
                shootButton: "拍照",
                alignPrompt: "請將患者臉部對準畫面中的輔助線。",
                photoPreview: "照片預覽",
                photoNum: "第 {count} 張",
                analyzeQuality: "分析照片品質 ✨",
                analyzing: "分析中...",
                retakeThis: "重新拍攝此張",
                continueShooting: "繼續拍攝",
                finishShooting: "完成拍攝",
                allPhotosPreview: "所有照片預覽",
                downloadAll: "一鍵下載全部照片",
                downloadThis: "下載此張",
                retakeSingle: "單獨重拍",
                retakeAll: "重新拍攝所有照片",
                downloadOrRetake: "您可以下載單張或全部照片，或選擇重新拍攝。",
                generatingReport: "生成綜合報告中...",
                modalUnderstood: "我明白了",
                photoAngleNames: ["正面", "側面", "側面45°"],
                photoNotes: [
                   `<p class="text-red-600 font-bold text-3xl mb-6">請站於患者正對面再做拍攝</p><p class="text-lg leading-relaxed text-gray-700">請將患者臉部對準畫面中央的輪廓線，確保正面對稱、耳朵與臉頰輪廓完整露出，並請患者直視鏡頭。</p>`,
                   `<p class="text-red-600 font-bold text-3xl mb-6">請站於患者正側面再做拍攝</p><p class="text-lg leading-relaxed text-gray-700">請將患者側面輪廓對準畫面中央，方便確認咬合平面及嘴唇豐隆度。</p>`,
                   `<p class="text-red-600 font-bold text-3xl mb-6">請站於患者側方45°再做拍攝</p><p class="text-lg leading-relaxed text-gray-700">請將患者45度側面輪廓對準畫面中央，輔助確認美觀及豐隆度。</p>`
                ],
                testShooting: "測試拍照",
           },
           'en': {
                title: "CMP Patient Photo Tool.Beta",
                home: "Home",
                introTitle: "CMP Patient Photo Tool",
                introDesc1: "This tool is designed to help dentists take facial photos of patients quickly and easily.",
                introDesc2: "These photos serve as a crucial reference for CMP technicians when creating dentures.",
                introDesc3: "This session will guide you to capture 3 angles:",
                introAngles: "Front, Profile, 45° Profile",
                introDesc4: "Please follow the instructions. Thank you for your cooperation!",
                startShooting: "Start Shooting",
                testVersionNote: "This software is a beta version and may not function correctly on all mobile models. If you encounter any issues, please contact us for optimization and correction. Thank you for your understanding.",
                geminiCredit: "This software is proudly built with Google Gemini",
                shooting: "Shooting",
                pleaseShoot: "Please capture the patient's",
                facePhoto: "facial photo",
                faceDetection: {
                    noFace: "Detecting face... Please place the face in the viewfinder.",
                    lookStraight: "Please ask the patient to look straight at the camera.",
                    centerFace: "Please center the face and ensure the contour is fully visible.",
                    ready: "✅ Face ready for capture!",
                    readySide: "✅ Face detected, ready for capture!",
                    detectingSide: "Detecting face... Please place the face in the center.",
                },
                zoomIn: "Zoom In",
                zoomOut: "Zoom Out",
                shootButton: "Capture",
                alignPrompt: "Please align the patient's face with the guide lines.",
                photoPreview: "Photo Preview",
                photoNum: "Photo {count}",
                analyzeQuality: "Analyze Photo Quality ✨",
                analyzing: "Analyzing...",
                retakeThis: "Retake This Photo",
                continueShooting: "Continue",
                finishShooting: "Finish Shooting",
                allPhotosPreview: "All Photos Preview",
                downloadAll: "Download All Photos",
                downloadThis: "Download This",
                retakeSingle: "Retake This",
                retakeAll: "Retake All Photos",
                downloadOrRetake: "You can download individual photos, all photos, or choose to retake.",
                generatingReport: "Generating summary report...",
                modalUnderstood: "I Understand",
                photoAngleNames: ["Front", "Profile", "45° Profile"],
                photoNotes: [
                   `<p class="text-red-600 font-bold text-3xl mb-6">Please stand directly in front of the patient</p><p class="text-lg leading-relaxed text-gray-700">Align the patient's face with the central outline, ensuring frontal symmetry and that the ears and jawline are fully visible. Ask the patient to look directly at the camera.</p>`,
                   `<p class="text-red-600 font-bold text-3xl mb-6">Please stand at the patient's direct side</p><p class="text-lg leading-relaxed text-gray-700">Align the patient's side profile to the center of the screen to check the occlusal plane and lip fullness.</p>`,
                   `<p class="text-red-600 font-bold text-3xl mb-6">Please stand at a 45° angle to the patient</p><p class="text-lg leading-relaxed text-gray-700">Align the patient's 45-degree profile to the center to help assess aesthetics and fullness.</p>`
                ],
                testShooting: "Test Capture",
           }
       };

       // Helper function remains unchanged
       const checkEyesLookingStraight = (landmarks, videoHeight) => {
           if (!landmarks) return false;
           const leftEye = landmarks.getLeftEye(); const rightEye = landmarks.getRightEye(); const nose = landmarks.getNose();
           if (leftEye.length === 0 || rightEye.length === 0 || nose.length < 4) return false;
           const getAverageY = (points) => points.reduce((sum, p) => sum + p.y, 0) / points.length;
           const leftEyeAvgY = getAverageY(leftEye); const rightEyeAvgY = getAverageY(rightEye);
           const eyeLevelThreshold = 0.02 * videoHeight;
           const areEyesLevel = Math.abs(leftEyeAvgY - rightEyeAvgY) < eyeLevelThreshold;
           const noseTip = nose[3];
           const leftEyeCenterX = leftEye.reduce((sum, p) => sum + p.x, 0) / leftEye.length;
           const rightEyeCenterX = rightEye.reduce((sum, p) => sum + p.x, 0) / rightEye.length;
           const eyeMidpointX = (leftEyeCenterX + rightEyeCenterX) / 2;
           const noseAlignmentThreshold = 0.03 * videoHeight;
           const isNoseAligned = Math.abs(noseTip.x - eyeMidpointX) < noseAlignmentThreshold;
           return areEyesLevel && isNoseAligned;
       };

       // Modal Component with no title
       const Modal = ({ message, isVisible, onClose, closeButtonText }) => {
           if (!isVisible) return null;
           return (
               <div className="modal-overlay">
                   <div className="modal-content">
                       <div className="modal-message" dangerouslySetInnerHTML={{ __html: message }}></div>
                       <button onClick={onClose} className="modal-close-button">
                           {closeButtonText}
                       </button>
                   </div>
               </div>
           );
       };

       function App() {
           const [lang, setLang] = useState('zh-TW');
           const T = translations[lang];

           const videoRef = useRef(null);
           const photoCanvasRef = useRef(null);
           const faceDetectionIntervalRef = useRef(null);

           const [appState, setAppState] = useState('intro');
           const [loadingMessage, setLoadingMessage] = useState("載入攝影機中...");
           const [cameraError, setCameraError] = useState(false);
           const [isCameraReady, setIsCameraReady] = useState(false);
           const [modelsInitialized, setModelsInitialized] = useState(false);
           const [capturedImages, setCapturedImages] = useState([]);
           const MAX_PHOTOS = 3;
           const [photoCount, setPhotoCount] = useState(0);

           const [zoomLevel, setZoomLevel] = useState(1.0);
           const ZOOM_STEP = 0.1; // Define ZOOM_STEP for consistency
           const MIN_ZOOM = 1.0; // Define MIN_ZOOM for consistency
           const MAX_ZOOM = 3.0; // Define MAX_ZOOM for consistency
           const [focusPoint, setFocusPoint] = useState({ x: 50, y: 50, visible: false });

           // AI and other states remain the same
           const [llmTip, setLlmTip] = useState('');
           const [isLlmLoading, setIsLlmLoading] = useState(false);
           const [analysisResult, setAnalysisResult] = useState('');
           const [isAnalysisLoading, setIsAnalysisLoading] = useState(false);
           const [summaryReport, setSummaryReport] = useState('');
           const [isSummaryLoading, setIsSummaryLoading] = useState(false);

           const [faceDetected, setFaceDetected] = useState(false);
           const [faceReadyForFrontPhoto, setFaceReadyForFrontPhoto] = useState(false);
           const [gazeStraight, setGazeStraight] = useState(false);

           const [showModal, setShowModal] = useState(false);
           const [modalMessage, setModalMessage] = useState('');

           const loadFaceModels = useCallback(async () => {
                try {
                   setLoadingMessage("載入人臉辨識模型中...");
                   const weightsPath = 'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/';
                   await faceapi.nets.tinyFaceDetector.loadFromUri(weightsPath);
                   await faceapi.nets.faceLandmark68Net.loadFromUri(weightsPath);
                   setLoadingMessage("人臉辨識模型載入完成。");
                   setModelsInitialized(true);
                   return true;
               } catch (error) {
                   console.error("Error loading face models:", error);
                   setLoadingMessage("錯誤: 載入人臉辨識模型失敗。請檢查網路連線或稍後再試。");
                   setCameraError(true);
                   setModelsInitialized(true);
                   return false;
               }
           }, []);

           const startVideo = useCallback(async () => {
                setLoadingMessage("啟動攝影機中...");
               setCameraError(false);
               setIsCameraReady(false);
               try {
                   const stream = await navigator.mediaDevices.getUserMedia({
                       video: {
                           facingMode: { exact: "environment" },
                           width: { ideal: 3840, min: 2560 }, // Try for 4K or at least 2.5K
                           height: { ideal: 2160, min: 1440 }, // Try for 4K or at least 1.4K
                           frameRate: { ideal: 30, min: 24 }
                       }
                   });
                   if (videoRef.current) {
                       videoRef.current.srcObject = stream;
                       videoRef.current.onloadedmetadata = async () => {
                           try {
                               await videoRef.current.play();
                               setLoadingMessage("攝影機已啟動。");
                               setIsCameraReady(true);
                               await generatePhotoTip(); // Generate tip when camera starts

                               // Clear any existing interval before starting a new one
                               if (faceDetectionIntervalRef.current) clearInterval(faceDetectionIntervalRef.current);

                               // Start face detection loop
                               faceDetectionIntervalRef.current = setInterval(async () => {
                                   if (videoRef.current && !videoRef.current.paused) {
                                       const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();

                                       let currentFaceDetected = detections.length > 0;
                                       let currentFaceReadyForFrontPhoto = false;
                                       let currentGazeStraight = false;

                                       const videoElement = videoRef.current;
                                       const videoWidth = videoElement.videoWidth;
                                       const videoHeight = videoElement.videoHeight;

                                       if (photoCount === 0) { // Specific checks for frontal photo
                                           if (currentFaceDetected && detections[0]) {
                                               const { detection, landmarks } = detections[0];
                                               const { box } = detection;

                                               // Define a reasonable central zone for face detection
                                               const centralZone_x_min = videoWidth * 0.35;
                                               const centralZone_x_max = videoWidth * 0.65;
                                               const centralZone_y_min = videoHeight * 0.3;
                                               const centralZone_y_max = videoHeight * 0.7;

                                               const faceCenterX = box.x + box.width / 2;
                                               const faceCenterY = box.y + box.height / 2;

                                               const isCentered = (
                                                   faceCenterX >= centralZone_x_min && faceCenterX <= centralZone_x_max &&
                                                   faceCenterY >= centralZone_y_min && faceCenterY <= centralZone_y_max
                                               );

                                               // Check if face contour is complete (not cut off at edges)
                                               const edge_padding_x = videoWidth * 0.02; // 2% padding from edges
                                               const edge_padding_y = videoHeight * 0.02; // 2% padding from edges
                                               const isContourComplete = (
                                                   box.x >= edge_padding_x &&
                                                   box.y >= edge_padding_y &&
                                                   (box.x + box.width) <= (videoWidth - edge_padding_x) &&
                                                   (box.y + box.height) <= (videoHeight - edge_padding_y)
                                               );

                                               currentGazeStraight = checkEyesLookingStraight(landmarks, videoHeight);

                                               currentFaceReadyForFrontPhoto = isCentered && isContourComplete && currentGazeStraight;
                                           } else {
                                               currentFaceReadyForFrontPhoto = false; // No face detected or not centered/complete
                                           }
                                           setFaceReadyForFrontPhoto(currentFaceReadyForFrontPhoto);
                                           setGazeStraight(currentGazeStraight);
                                       } else { // For side photos, just need any face detected
                                           setFaceReadyForFrontPhoto(currentFaceDetected); // Using this state for general face detection when not frontal
                                           setGazeStraight(true); // Gaze straight not strictly required for side profiles, so assume true if face is detected.
                                       }
                                       setFaceDetected(currentFaceDetected);
                                   }
                               }, 250); // Run detection every 250ms
                           } catch (playError) {
                               console.error("Error playing video:", playError);
                               setLoadingMessage("錯誤: 攝影機無法播放。");
                               setCameraError(true);
                           }
                       };
                       videoRef.current.onerror = () => {
                           setLoadingMessage("錯誤：攝影機串流時發生問題。");
                           setCameraError(true);
                       };
                   }
               } catch (err) {
                   console.error("Error accessing camera:", err);
                   if (err.name === "OverconstrainedError") {
                       setLoadingMessage("錯誤：無法滿足攝影機請求規格。您的裝置可能不支援後置攝影機或請求的解析度。");
                   } else if (err.name === "NotAllowedError") {
                       setLoadingMessage("錯誤：攝影機權限未授予。請允許瀏覽器使用攝影機。");
                   } else if (err.name === "NotFoundError" || err.name === "DevicesNotFoundError") {
                       setLoadingMessage("錯誤：找不到後置攝影機。請確保攝影機已連接且正常運作。");
                   } else {
                       setLoadingMessage(`錯誤：無法取得後置攝影機。詳情: ${err.message}`);
                   }
                   setCameraError(true);
               }
           }, [photoCount, generatePhotoTip]);

           // Effect hook to manage camera and model loading based on app state
           useEffect(() => {
                let cleanupFunction = () => {};
               const initAppFlow = async () => {
                   if (appState === 'camera' && !showModal) {
                       // Only load models and start camera if in camera state and modal is not showing
                       if (!modelsInitialized) {
                           await loadFaceModels();
                       }
                       // If models are initialized and no camera error, start the video
                       if (modelsInitialized && !cameraError) {
                           startVideo();
                           // Clear any previous LLM related messages
                           setLlmTip('');
                           setAnalysisResult('');
                           setSummaryReport('');
                       }
                       cleanupFunction = () => {
                           // Stop camera stream and clear interval when leaving camera state
                           if (videoRef.current && videoRef.current.srcObject) {
                               videoRef.current.srcObject.getTracks().forEach(track => track.stop());
                               videoRef.current.srcObject = null;
                           }
                           if (faceDetectionIntervalRef.current) {
                               clearInterval(faceDetectionIntervalRef.current);
                               faceDetectionIntervalRef.current = null;
                           }
                       };
                   } else if (appState !== 'camera') {
                       // If not in camera state, ensure camera is stopped
                       if (videoRef.current && videoRef.current.srcObject) {
                           videoRef.current.srcObject.getTracks().forEach(track => track.stop());
                           videoRef.current.srcObject = null;
                       }
                       if (faceDetectionIntervalRef.current) {
                           clearInterval(faceDetectionIntervalRef.current);
                           faceDetectionIntervalRef.current = null;
                       }
                   }
               };
               initAppFlow();
               // Cleanup function runs when component unmounts or dependencies change
               return () => cleanupFunction();
           }, [appState, loadFaceModels, startVideo, modelsInitialized, cameraError, showModal]);

           // Handle photo capture
           const handleCapturePhoto = () => {
               // Only allow capture if camera is ready and face detection criteria are met
               const canCapture = isCameraReady && (photoCount === 0 ? faceReadyForFrontPhoto : faceDetected);

               if (videoRef.current && photoCanvasRef.current && canCapture) {
                   // Stop face detection when a photo is taken
                   if (faceDetectionIntervalRef.current) {
                       clearInterval(faceDetectionIntervalRef.current);
                       faceDetectionIntervalRef.current = null;
                   }
                   setFaceDetected(false); // Reset face detection states
                   setFaceReadyForFrontPhoto(false);
                   setGazeStraight(false);

                   const video = videoRef.current;
                   const photoCanvas = photoCanvasRef.current;

                   // Set canvas dimensions to video dimensions
                   photoCanvas.width = video.videoWidth;
                   photoCanvas.height = video.videoHeight;
                   const context = photoCanvas.getContext('2d');

                   // Calculate scaled dimensions and offset for zooming
                   const scaledWidth = video.videoWidth / zoomLevel;
                   const scaledHeight = video.videoHeight / zoomLevel;
                   const offsetX = (video.videoWidth - scaledWidth) / 2;
                   const offsetY = (video.videoHeight - scaledHeight) / 2;

                   // Draw the video frame onto the canvas, applying zoom
                   context.drawImage(video, offsetX, offsetY, scaledWidth, scaledHeight, 0, 0, photoCanvas.width, photoCanvas.height);

                   const imageDataUrl = photoCanvas.toDataURL('image/jpeg', 1.0); // Get image data URL

                   // Update captured images, replacing if retaking or adding new
                   setCapturedImages(prevImages => {
                       const newImages = [...prevImages];
                       newImages[photoCount] = imageDataUrl; // Store image at current photoCount index
                       setAppState('single_photo_preview'); // Go to single photo preview
                       return newImages;
                   });
                   setAnalysisResult(''); // Clear previous analysis result
                   setSummaryReport(''); // Clear previous summary report
               }
           };

           // Handle a test capture (skips face detection checks)
           const handleTestCapturePhoto = () => {
               if (videoRef.current && photoCanvasRef.current && isCameraReady) {
                   if (faceDetectionIntervalRef.current) {
                       clearInterval(faceDetectionIntervalRef.current);
                       faceDetectionIntervalRef.current = null;
                   }
                   setFaceDetected(false);
                   setFaceReadyForFrontPhoto(false);
                   setGazeStraight(false);

                   const video = videoRef.current;
                   const photoCanvas = photoCanvasRef.current;

                   photoCanvas.width = video.videoWidth;
                   photoCanvas.height = video.videoHeight;
                   const context = photoCanvas.getContext('2d');

                   const scaledWidth = video.videoWidth / zoomLevel;
                   const scaledHeight = video.videoHeight / zoomLevel;
                   const offsetX = (video.videoWidth - scaledWidth) / 2;
                   const offsetY = (video.videoHeight - scaledHeight) / 2;

                   context.drawImage(video, offsetX, offsetY, scaledWidth, scaledHeight, 0, 0, photoCanvas.width, photoCanvas.height);
                   const imageDataUrl = photoCanvas.toDataURL('image/jpeg', 1.0);

                   setCapturedImages(prevImages => {
                       const newImages = [...prevImages];
                       newImages[photoCount] = imageDataUrl;
                       setAppState('single_photo_preview');
                       return newImages;
                   });
                   setAnalysisResult('');
                   setSummaryReport('');
               }
           };

           // Download a single photo
           const handleDownloadPhoto = (imageDataUrl, index) => {
               const now = new Date();
               const timestamp = `${now.getFullYear()}${String(now.getMonth() + 1).padStart(2, '0')}${String(now.getDate()).padStart(2, '0')}_${String(now.getHours()).padStart(2, '0')}${String(now.getMinutes()).padStart(2, '0')}${String(now.getSeconds()).padStart(2, '0')}`;
               const link = document.createElement('a');
               link.href = imageDataUrl;
               link.download = `CMP_Patient_${timestamp}_${T.photoAngleNames[index] || 'photo'}.jpeg`;
               document.body.appendChild(link);
               link.click();
               document.body.removeChild(link);
           };

           // Download all captured photos
           const handleDownloadAllPhotos = () => {
               capturedImages.forEach((image, index) => {
                   setTimeout(() => {
                       handleDownloadPhoto(image, index);
                   }, index * 300); // Add a small delay for each download
               });
           };

           // Retake the currently displayed photo
           const handleRetakeCurrentPhoto = () => {
               setModalMessage(T.photoNotes[photoCount]); // Show specific note for the current angle
               setShowModal(true);
           };

           // Retake a specific photo from the all photos preview
           const handleRetakeSinglePhoto = (indexToRetake) => {
               setPhotoCount(indexToRetake);
               setModalMessage(T.photoNotes[indexToRetake]); // Show specific note for the retaken angle
               setShowModal(true);
           };

           // Continue to the next photo or finish
           const handleContinueShooting = () => {
               const nextPhotoIndex = photoCount + 1;
               if (nextPhotoIndex === MAX_PHOTOS) {
                   setAppState('all_photos_preview'); // If all photos taken, go to all photos preview
               } else {
                   setPhotoCount(nextPhotoIndex);
                   setModalMessage(T.photoNotes[nextPhotoIndex]); // Show note for the next angle
                   setShowModal(true);
               }
               setLlmTip(''); // Clear LLM tip
               setAnalysisResult(''); // Clear analysis result
           };

           // Reset and retake all photos
           const handleRetakeAllPhotos = () => {
               setCapturedImages([]); // Clear all captured images
               setPhotoCount(0); // Reset photo count to 0
               setModalMessage(T.photoNotes[0]); // Show the first photo note
               setShowModal(true);
               setAnalysisResult(''); // Clear analysis result
               setSummaryReport(''); // Clear summary report
           };

           // Modal close handler: transition to camera state after modal is dismissed
           const handleCloseModalAndStartCamera = () => {
               setShowModal(false);
               setAppState('camera');
           };

           // Zoom functions
           const handleZoomIn = () => {
               setZoomLevel(prevZoom => Math.min(prevZoom + ZOOM_STEP, MAX_ZOOM));
           };

           const handleZoomOut = () => {
               setZoomLevel(prevZoom => Math.max(prevZoom - ZOOM_STEP, MIN_ZOOM));
           };

           // Handle click for focus point visual feedback
           const handleFocusClick = (e) => {
                if (!videoRef.current || !isCameraReady || !videoRef.current.srcObject) return; // Prevent focus if camera not ready
                const videoElement = videoRef.current;
                const rect = videoElement.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                // Set focus point as percentage for responsive positioning
                setFocusPoint({ x: (x / rect.width) * 100, y: (y / rect.height) * 100, visible: true });
                // Hide focus point after a short delay
                setTimeout(() => setFocusPoint(prev => ({ ...prev, visible: false })), 2000);
           };

           // Simulate LLM call for photo tips
           const generatePhotoTip = useCallback(async () => {
                if (photoCount < T.photoNotes.length) {
                    setIsLlmLoading(true);
                    setLlmTip('生成拍照提示中...');
                    // Simulate API call with a delay
                    setTimeout(() => {
                        setLlmTip(T.photoNotes[photoCount]); // Display the specific note for the current angle
                        setIsLlmLoading(false);
                    }, 1000);
                } else {
                    setLlmTip(''); // Clear tip if all photos are taken
                }
           }, [photoCount, T]); // T added to dependencies for translation updates


           // Simulate LLM call for photo quality analysis
           const handleAnalyzePhoto = useCallback(async (imageDataUrl) => {
               setIsAnalysisLoading(true);
               setAnalysisResult(T.analyzing);
               // Simulate API call with a delay
               setTimeout(() => {
                   let analysis;
                   if (Math.random() > 0.5) {
                       analysis = "這張照片品質良好，光線充足且對焦清晰，面部特徵清晰可見。"; // Example good quality
                   } else {
                       analysis = "這張照片可能需要改進。請確保光線均勻，避免陰影，並確保患者姿勢正確，例如直視鏡頭或按指示轉動角度。"; // Example needs improvement
                   }
                   setAnalysisResult(analysis);
                   setIsAnalysisLoading(false);
               }, 2000); // Simulate network delay
           }, [lang, T]); // T added to dependencies

           // Simulate LLM call for generating a summary report
           const handleGenerateSummaryReport = useCallback(async () => {
               setIsSummaryLoading(true);
               setSummaryReport(T.generatingReport);
               // Simulate API call with a delay
               setTimeout(() => {
                   let report = "綜合報告：\n\n";
                   capturedImages.forEach((_, index) => {
                       report += `${T.photoAngleNames[index]} 照片：已成功拍攝並保存。`;
                       // Add more simulated details if needed for a richer report
                       if (index === 0) report += " 正面照片用於評估整體面部對稱性及中線。\n";
                       else if (index === 1) report += " 側面照片用於評估咬合平面及唇部豐隆度。\n";
                       else if (index === 2) report += " 45度側面照片用於評估側面美觀及立體感。\n";
                   });
                   report += "\n\n所有照片均已妥善記錄，並準備好進行下一步處理。";
                   setSummaryReport(report);
                   setIsSummaryLoading(false);
               }, 3000); // Simulate network delay
           }, [capturedImages, T]); // T added to dependencies


           return (
               <div className={`min-h-screen bg-gradient-to-br from-stone-100 to-stone-200 flex items-center justify-center ${appState === 'camera' ? 'p-0' : 'p-4'} font-inter text-gray-800`}>
                   <div className={`bg-white shadow-xl ${appState === 'camera' ? 'p-0 w-full h-screen' : 'w-full max-w-4xl rounded-2xl'} border border-blue-200`}>
                       {/* Home button always visible except on intro screen */}
                       {appState !== 'intro' && (
                           <div className="absolute top-4 right-4 z-20">
                               <button onClick={() => {
                                   setAppState('intro');
                                   setCapturedImages([]); // Clear images when going home
                                   setPhotoCount(0); // Reset photo count
                                   setAnalysisResult('');
                                   setSummaryReport('');
                                   if (videoRef.current && videoRef.current.srcObject) { // Ensure camera is stopped
                                       videoRef.current.srcObject.getTracks().forEach(track => track.stop());
                                       videoRef.current.srcObject = null;
                                   }
                                   if (faceDetectionIntervalRef.current) { // Clear detection interval
                                       clearInterval(faceDetectionIntervalRef.current);
                                       faceDetectionIntervalRef.current = null;
                                   }
                               }} className="p-3 bg-blue-500 text-white rounded-full shadow-lg hover:bg-blue-600 transition-colors duration-200 flex items-center justify-center text-sm">
                                   <i className="fas fa-home mr-2"></i> {T.home}
                               </button>
                           </div>
                       )}

                       {/* Intro Screen */}
                       {appState === 'intro' && (
                           <div className="flex flex-col h-full w-full p-6">
                               <header className="w-full flex justify-end">
                                   <div className="flex gap-2">
                                       <button onClick={() => setLang('zh-TW')} className={`px-4 py-1 text-sm rounded-full transition-colors ${lang === 'zh-TW' ? 'bg-blue-600 text-white shadow-md' : 'bg-gray-200 text-gray-700'}`}>繁體中文</button>
                                       <button onClick={() => setLang('en')} className={`px-4 py-1 text-sm rounded-full transition-colors ${lang === 'en' ? 'bg-blue-600 text-white shadow-md' : 'bg-gray-200 text-gray-700'}`}>English</button>
                                   </div>
                               </header>
                               <main className="flex-grow flex flex-col items-center justify-center text-center">
                                   <h1 className="text-4xl font-extrabold text-blue-800 mb-6"><i className="fas fa-tooth mr-3 text-blue-600"></i>{T.introTitle}</h1>
                                   <p className="text-lg text-gray-700 mb-6 max-w-2xl mx-auto leading-relaxed">{T.introDesc1}<br/>{T.introDesc2}<br/><br/>{T.introDesc3}<br/><span className="font-bold text-2xl text-red-600 flex items-center justify-center gap-4">{T.introAngles}</span><br/>{T.introDesc4}</p>
                                   <button
                                       onClick={() => { setPhotoCount(0); setModalMessage(T.photoNotes[0]); setShowModal(true); }}
                                       className="px-12 py-5 bg-blue-600 text-white rounded-full font-bold text-2xl shadow-lg hover:bg-blue-700 transition-all duration-300 transform hover:scale-105 active:scale-95 z-10 mt-8">
                                       <i className="fas fa-camera mr-3"></i>{T.startShooting}
                                   </button>
                               </main>
                               <footer className="w-full text-center mt-auto pt-6">
                                   <p className="text-xs text-gray-500 max-w-lg mx-auto">{T.testVersionNote}</p>
                                   <p className="mt-2 text-base text-gray-600">✨ {T.geminiCredit}</p>
                               </footer>
                           </div>
                       )}

                       {/* Camera Screen */}
                       {appState === 'camera' && (
                           <div className="flex flex-col h-full w-full relative p-4 pb-0">
                               {/* Test Capture Button */}
                               <div className="absolute top-4 left-4 z-20">
                                   <button onClick={handleTestCapturePhoto} disabled={!isCameraReady || cameraError} className={`px-4 py-2 rounded-full text-white font-bold text-sm shadow-lg transform transition-all duration-300 ${isCameraReady && !cameraError ? 'bg-purple-500 hover:bg-purple-600 active:scale-95' : 'bg-gray-400 cursor-not-allowed'}`}>
                                       <i className="fas fa-vial mr-2"></i> {T.testShooting}
                                   </button>
                               </div>

                               <h2 className="text-2xl font-bold text-center text-blue-700 pt-4 mb-4">
                                   <i className="fas fa-video mr-2"></i>{T.shooting}
                               </h2>
                               <div className="mb-6 text-center">
                                    <p className="text-xl font-bold text-blue-800 animate-pulse flex items-center justify-center">
                                        {T.pleaseShoot} <span className="text-red-600 flex items-center ml-2">{T.photoAngleNames[photoCount]}</span> {T.facePhoto}
                                    </p>
                               </div>
                               <div className="relative w-full flex-grow bg-gray-900 overflow-hidden border border-gray-300 flex items-center justify-center cursor-pointer video-container" onClick={handleFocusClick}>
                                   {/* Video stream container with zoom */}
                                   <div className="absolute inset-0 flex items-center justify-center" style={{ transform: `scale(${zoomLevel})`, transformOrigin: 'center center', width: '100%', height: '100%' }}>
                                       <video ref={videoRef} className="w-full h-full object-contain" autoPlay muted playsInline></video>
                                       <div className="overlay-elements" style={{ zIndex: 10 }}>
                                           {/* NEW, FINAL, CENTERED SVG OVERLAY */}
                                           {photoCount === 0 && (
                                               <svg className="absolute w-full h-full" viewBox="0 0 800 600" fill="none" xmlns="http://www.w3.org/2000/svg" style={{zIndex: 15, pointerEvents: 'none'}}>
                                                   {/* Face Outline */}
                                                   <path d="M400 500 C300 500 250 400 250 300 C250 175 315 150 400 150 C485 150 550 175 550 300 C550 400 500 500 400 500Z" stroke="white" strokeWidth="3" strokeDasharray="12 6" />
                                                   {/* Eyes */}
                                                   <ellipse cx="330" cy="290" rx="55" ry="25" stroke="white" strokeWidth="3" strokeDasharray="12 6"/>
                                                   <ellipse cx="470" cy="290" rx="55" ry="25" stroke="white" strokeWidth="3" strokeDasharray="12 6"/>
                                                   {/* Nose */}
                                                   <path d="M400 310 L380 380 L420 380" stroke="white" strokeWidth="3" strokeDasharray="12 6" strokeLinejoin="round" />
                                               </svg>
                                           )}
                                           {/* Guide Grid */}
                                           <div className="absolute inset-0 grid grid-cols-3 grid-rows-3 pointer-events-none" style={{ zIndex: 11 }}>
                                               {Array(9).fill(0).map((_, i) => (
                                                   <div key={i} className="border border-white border-opacity-30" style={{ borderTopWidth: i < 3 ? 0 : '1px', borderLeftWidth: i % 3 === 0 ? 0 : '1px' }}></div>
                                               ))}
                                           </div>
                                           {/* Center Crosshairs */}
                                           <div className="absolute top-0 bottom-0 left-1/2 w-px bg-white opacity-50" style={{ transform: 'translateX(-50%)', zIndex: 12 }}></div>
                                           <div className="absolute left-0 right-0 top-1/2 h-px bg-white opacity-50" style={{ transform: 'translateY(-50%)', zIndex: 12 }}></div>
                                       </div>
                                   </div>
                                   {/* Focus Point Indicator */}
                                   {focusPoint.visible && (
                                       <div className="absolute w-12 h-12 border-4 border-yellow-400 rounded-full animate-ping-once" style={{ left: `${focusPoint.x}%`, top: `${focusPoint.y}%`, transform: 'translate(-50%, -50%)', zIndex: 20 }}></div>
                                   )}
                                   {/* Camera Error Message */}
                                   {cameraError && (
                                       <div className="absolute inset-0 flex items-center justify-center bg-red-800 bg-opacity-90 text-white text-lg font-semibold p-4 text-center rounded-xl z-20">
                                           {loadingMessage}
                                       </div>
                                   )}
                                   {/* Camera Loading Message */}
                                   {!isCameraReady && !cameraError && (
                                       <div className="absolute inset-0 flex items-center justify-center bg-black bg-opacity-70 text-white text-lg font-semibold p-4 text-center rounded-xl z-20">
                                           {loadingMessage}
                                       </div>
                                   )}
                               </div>
                               {/* Face Detection Status */}
                               {isCameraReady && !cameraError && (
                                   <div className={`mt-4 text-center font-bold ${(photoCount === 0 && faceReadyForFrontPhoto) || (photoCount > 0 && faceDetected) ? 'text-green-500' : 'text-yellow-500'}`}>
                                       {photoCount === 0 ?
                                           (!faceDetected ? T.faceDetection.noFace :
                                            !gazeStraight ? T.faceDetection.lookStraight :
                                            !faceReadyForFrontPhoto ? T.faceDetection.centerFace :
                                            T.faceDetection.ready)
                                           :
                                           (faceDetected ? T.faceDetection.readySide : T.faceDetection.detectingSide)
                                       }
                                   </div>
                               )}
                               {/* LLM Tip (Simulated) */}
                               {isLlmLoading && <p className="text-center text-blue-500 mt-2">{llmTip}</p>}
                               {!isLlmLoading && llmTip && (photoCount === 0 && (!faceDetected || !gazeStraight || !faceReadyForFrontPhoto)) && (
                                    <div className="mt-4 p-3 bg-blue-100 text-blue-800 rounded-lg text-center text-sm">
                                        <p dangerouslySetInnerHTML={{ __html: llmTip }}></p>
                                    </div>
                               )}
                               {/* Camera Controls */}
                               <div className="flex flex-wrap items-center justify-center gap-3 py-6">
                                   <button onClick={handleZoomOut} disabled={!isCameraReady || cameraError || zoomLevel <= MIN_ZOOM} className={`px-4 py-2 rounded-full text-white font-bold text-base shadow-lg transform transition-all duration-300 ${isCameraReady && !cameraError && zoomLevel > MIN_ZOOM ? 'bg-blue-500 hover:bg-blue-600 active:scale-95' : 'bg-gray-400 cursor-not-allowed'}`}>
                                       <i className="fas fa-minus mr-1"></i> {T.zoomOut}
                                   </button>
                                   <button
                                       onClick={handleCapturePhoto}
                                       disabled={!isCameraReady || cameraError || !(photoCount === 0 ? faceReadyForFrontPhoto : faceDetected)}
                                       className={`px-5 py-2 rounded-full text-white font-bold text-base shadow-lg transform transition-all duration-300 ${(isCameraReady && !cameraError && ((photoCount === 0 && faceReadyForFrontPhoto) || (photoCount > 0 && faceDetected))) ? 'bg-green-500 hover:bg-green-600 active:scale-95' : 'bg-gray-400 cursor-not-allowed'}`}
                                   >
                                       <i className="fas fa-camera mr-1"></i> {T.shootButton} ({photoCount + 1}/{MAX_PHOTOS})
                                   </button>
                                   <button onClick={handleZoomIn} disabled={!isCameraReady || cameraError || zoomLevel >= MAX_ZOOM} className={`px-4 py-2 rounded-full text-white font-bold text-base shadow-lg transform transition-all duration-300 ${isCameraReady && !cameraError && zoomLevel < MAX_ZOOM ? 'bg-blue-500 hover:bg-blue-600 active:scale-95' : 'bg-gray-400 cursor-not-allowed'}`}>
                                       <i className="fas fa-plus mr-1"></i> {T.zoomIn}
                                   </button>
                               </div>
                               <p className="text-sm text-gray-500 pb-4 text-center">{T.alignPrompt}</p>
                           </div>
                       )}

                       {/* Single Photo Preview Screen */}
                       {appState === 'single_photo_preview' && capturedImages.length > 0 && (
                           <div className="flex flex-col h-full w-full p-4">
                               <h2 className="text-2xl font-bold text-center text-blue-700 pt-4 mb-4">
                                   <i className="fas fa-image mr-2"></i>{T.photoPreview} <span className="text-red-600">{T.photoNum.replace('{count}', photoCount + 1)}</span>
                               </h2>
                               <div className="flex-grow flex items-center justify-center p-4">
                                   <div className="max-w-full max-h-full rounded-lg overflow-hidden shadow-lg border border-gray-300">
                                       <img src={capturedImages[photoCount]} alt={`${T.photoAngleNames[photoCount]} ${T.photoNum.replace('{count}', photoCount + 1)}`} className="w-full h-auto object-contain" />
                                   </div>
                               </div>
                               <div className="flex flex-col items-center mt-6">
                                   <button
                                       onClick={() => handleAnalyzePhoto(capturedImages[photoCount])}
                                       disabled={isAnalysisLoading}
                                       className={`px-8 py-3 rounded-full text-white font-bold text-lg shadow-lg transform transition-all duration-300 ${isAnalysisLoading ? 'bg-gray-400 cursor-not-allowed' : 'bg-purple-600 hover:bg-purple-700 active:scale-95'} mb-4`}
                                   >
                                       {isAnalysisLoading ? T.analyzing : T.analyzeQuality}
                                   </button>
                                   {analysisResult && (
                                       <p className="text-gray-700 text-center mb-4 px-4 text-lg">{analysisResult}</p>
                                   )}
                                   <div className="flex flex-wrap justify-center gap-4 mt-4">
                                       <button onClick={handleRetakeCurrentPhoto} className="px-6 py-3 bg-red-500 text-white rounded-full font-bold text-lg shadow-lg hover:bg-red-600 transition-all duration-300 transform hover:scale-105 active:scale-95">
                                           <i className="fas fa-redo mr-2"></i> {T.retakeThis}
                                       </button>
                                       <button onClick={handleContinueShooting} className="px-6 py-3 bg-blue-600 text-white rounded-full font-bold text-lg shadow-lg hover:bg-blue-700 transition-all duration-300 transform hover:scale-105 active:scale-95">
                                           <i className="fas fa-arrow-right mr-2"></i> {T.continueShooting}
                                       </button>
                                   </div>
                               </div>
                           </div>
                       )}

                       {/* All Photos Preview Screen */}
                       {appState === 'all_photos_preview' && (
                           <div className="flex flex-col h-full w-full p-4">
                               <h2 className="text-2xl font-bold text-center text-blue-700 pt-4 mb-6">
                                   <i className="fas fa-images mr-2"></i>{T.allPhotosPreview}
                               </h2>
                               <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 p-4">
                                   {capturedImages.map((image, index) => (
                                       <div key={index} className="flex flex-col items-center bg-gray-50 p-4 rounded-xl shadow-md border border-gray-200">
                                           <h3 className="text-lg font-semibold text-gray-800 mb-3">{T.photoAngleNames[index]}</h3>
                                           <img src={image} alt={`${T.photoAngleNames[index]}`} className="w-full h-48 object-contain rounded-lg mb-4 border border-gray-300"/>
                                           <div className="flex flex-col gap-2 w-full">
                                               <button onClick={() => handleDownloadPhoto(image, index)} className="flex items-center justify-center px-4 py-2 bg-green-500 text-white rounded-full font-bold text-sm shadow-md hover:bg-green-600 transition-colors duration-200">
                                                   <i className="fas fa-download mr-2"></i> {T.downloadThis}
                                               </button>
                                               <button onClick={() => handleRetakeSinglePhoto(index)} className="flex items-center justify-center px-4 py-2 bg-yellow-500 text-white rounded-full font-bold text-sm shadow-md hover:bg-yellow-600 transition-colors duration-200">
                                                   <i className="fas fa-sync-alt mr-2"></i> {T.retakeSingle}
                                               </button>
                                           </div>
                                       </div>
                                   ))}
                               </div>
                               <div className="flex flex-col items-center mt-8 px-4">
                                   <p className="text-gray-700 mb-6 text-center text-lg">{T.downloadOrRetake}</p>
                                   <div className="flex flex-wrap justify-center gap-4">
                                       <button
                                           onClick={handleDownloadAllPhotos}
                                           className="px-8 py-4 bg-purple-600 text-white rounded-full font-bold text-xl shadow-lg hover:bg-purple-700 transition-all duration-300 transform hover:scale-105 active:scale-95"
                                       >
                                           <i className="fas fa-file-download mr-3"></i> {T.downloadAll}
                                       </button>
                                       <button
                                           onClick={() => handleGenerateSummaryReport()}
                                           disabled={isSummaryLoading}
                                           className={`px-8 py-4 rounded-full text-white font-bold text-xl shadow-lg transform transition-all duration-300 ${isSummaryLoading ? 'bg-gray-400 cursor-not-allowed' : 'bg-blue-600 hover:bg-blue-700 active:scale-95'}`}
                                       >
                                           {isSummaryLoading ? T.generatingReport : '生成報告 ✨'}
                                       </button>
                                   </div>
                                   {summaryReport && (
                                       <div className="mt-8 p-6 bg-white rounded-xl shadow-md border border-gray-200 max-w-2xl w-full">
                                           <h3 className="text-xl font-bold text-blue-700 mb-4">綜合報告</h3>
                                           <p className="whitespace-pre-wrap text-gray-700 leading-relaxed">{summaryReport}</p>
                                       </div>
                                   )}
                                   <button onClick={handleRetakeAllPhotos} className="mt-8 px-8 py-3 bg-red-500 text-white rounded-full font-bold text-lg shadow-lg hover:bg-red-600 transition-all duration-300 transform hover:scale-105 active:scale-95">
                                       <i className="fas fa-trash-alt mr-2"></i> {T.retakeAll}
                                   </button>
                               </div>
                           </div>
                       )}

                       <canvas ref={photoCanvasRef} className="hidden"></canvas>
                   </div>
                   <Modal message={modalMessage} isVisible={showModal} onClose={handleCloseModalAndStartCamera} closeButtonText={T.modalUnderstood}/>
               </div>
           );
       }

       const container = document.getElementById('root');
       const root = createRoot(container);
       root.render(<App />);
   </script>
</body>
</html>
